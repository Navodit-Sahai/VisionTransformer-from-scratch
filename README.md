# VisionTransformer-from-scratch
This repository contains a complete implementation of the Vision Transformer (ViT) architecture built entirely from scratch using PyTorch. It breaks down the key components of ViT â€” from image patch embedding to transformer encoder layers â€” in a clear manner.

ðŸš€ Features
=> Implements image patch extraction and linear embedding
=> Custom Multi-Head Self-Attention and Feed-Forward Network
=> Supports positional encoding and class token
=> End-to-end training pipeline on image datasets (e.g., MNIST)
=> Well-commented code for step-by-step understanding
=> Modular and easy to extend for experimentation

ðŸŽ¯ Learning Goals
This project is designed to:
=> Understand how transformers process visual data
=> Learn how to build ViT components manually without heavy frameworks
